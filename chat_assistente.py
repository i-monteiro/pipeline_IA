import streamlit as st
import time
from openai import OpenAI
from elevenlabs import ElevenLabs
import os
from dotenv import load_dotenv
from datetime import datetime
import re

load_dotenv()

# ConfiguraÃ§Ã£o das chaves de API
OPENAI_API_KEY = os.getenv("API_KEY")
ELEVEN_API_KEY = os.getenv("ELEVEN_API_KEY")

# Verifique se as chaves estÃ£o carregadas corretamente
if not OPENAI_API_KEY or not ELEVEN_API_KEY:
    raise ValueError("As chaves de API nÃ£o foram carregadas corretamente. Verifique o arquivo .env.")

# Instanciar os clientes OpenAI e Eleven Labs
openai_client = OpenAI(api_key=OPENAI_API_KEY)
eleven_client = ElevenLabs(api_key=ELEVEN_API_KEY)

# ID do Assistente
ASSISTANT_ID = os.getenv("ASSISTANT_ID")

# FunÃ§Ã£o para converter texto em fala usando Eleven Labs
def text_to_speech(text):
    """Converte texto em Ã¡udio usando a API da Eleven Labs e retorna o Ã¡udio."""
    # Gera o Ã¡udio usando o modelo multilÃ­ngue
    audio_generator = eleven_client.generate(
        text=text,
        voice="nsQAxyXwUKBvqtEK9MfK",  # Use um ID de voz que suporte portuguÃªs
        model="eleven_multilingual_v2"  # Usa o modelo multilÃ­ngue para suportar portuguÃªs
    )
    
    # Converte o gerador em bytes
    audio_bytes = b''.join(list(audio_generator))  # Transforma o gerador em bytes
    
    return audio_bytes

# FunÃ§Ã£o para enviar a pergunta ao assistente e obter a resposta
def responder_pergunta(pergunta):
    # Cria um novo thread com a mensagem do usuÃ¡rio
    thread = openai_client.beta.threads.create(
        messages=[
            {
                "role": "user",
                "content": f"hoje Ã© dia {datetime.now()} {pergunta}",
            }
        ]
    )

    # Envia o thread para o assistente (como uma nova execuÃ§Ã£o)
    run = openai_client.beta.threads.runs.create(thread_id=thread.id, assistant_id=ASSISTANT_ID)
    st.write(f"ğŸ‘‰ Conversa id: {run.id}")

    # Aguarda a conclusÃ£o da execuÃ§Ã£o
    while run.status != "completed":
        run = openai_client.beta.threads.runs.retrieve(thread_id=thread.id, run_id=run.id)
        st.write(f"ğŸƒ Status da execuÃ§Ã£o: {run.status}")
        time.sleep(1)

    st.write("ğŸ ExecuÃ§Ã£o concluÃ­da!")

    # ObtÃ©m a Ãºltima mensagem do thread
    message_response = openai_client.beta.threads.messages.list(thread_id=thread.id)
    messages = message_response.data

    # Extrai e retorna a resposta mais recente
    latest_message = messages[0]
    resposta_texto = latest_message.content[0].text.value.strip()
    
    # Remove as citaÃ§Ãµes do texto
    resposta_texto = re.sub(r'ã€.*?ã€‘', '', resposta_texto)  # Linha adicionada
    
    # Converte a resposta em Ã¡udio
    resposta_audio = text_to_speech(resposta_texto)
    
    return resposta_texto, resposta_audio

# Interface do Streamlit
st.title("Agente de Atendimento - Pergunte ao Assistente")

# Caixa de entrada para perguntas
pergunta = st.text_input("Digite sua pergunta:")

# Quando uma pergunta Ã© feita, envia para o assistente e exibe a resposta
if pergunta:
    resposta_texto, resposta_audio = responder_pergunta(pergunta)
    st.write(f"ğŸ’¬ Resposta: {resposta_texto}")
    
    # Reproduz o Ã¡udio da resposta
    st.audio(resposta_audio, format='audio/mp3')
